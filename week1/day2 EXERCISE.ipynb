{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff... 100% ������������������������������������������������������ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6... 100% ������������������������������������������������������ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da... 100% ������������������������������������������������������ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9... 100% ������������������������������������������������������ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5... 100% ������������������������������������������������������   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051... 100% ������������������������������������������������������  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as images, videos, articles, and social media posts. This can help businesses save time and resources while also providing a unique voice and style.\n",
      "2. **Marketing Automation**: Generative AI can be used to automate marketing campaigns by generating personalized content, email subject lines, and even entire ad copy.\n",
      "3. **Customer Service**: Generative AI-powered chatbots can be used to provide 24/7 customer support, respond to common queries, and route complex issues to human representatives.\n",
      "4. **Product Design**: Generative AI can be used to design new product concepts, shapes, and features based on customer feedback and market trends.\n",
      "5. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, managing inventory, and identifying bottlenecks.\n",
      "6. **Financial Analysis**: Generative AI can be used to analyze large datasets, identify patterns, and make predictions about market trends and economic indicators.\n",
      "7. **Creative Writing**: Generative AI can be used to generate creative writing such as poetry, short stories, and even entire books.\n",
      "8. **Music Composition**: Generative AI can be used to compose music for advertising campaigns, video games, or even entire albums.\n",
      "9. **Fashion Design**: Generative AI can be used to design new fashion collections based on trends, customer feedback, and sustainable materials.\n",
      "10. **Predictive Maintenance**: Generative AI can be used to predict equipment failures, schedule maintenance, and optimize resource allocation.\n",
      "\n",
      "Some specific business use cases for Generative AI include:\n",
      "\n",
      "* **IBM's Watson Health**: A healthcare platform that uses Generative AI to analyze medical data and provide personalized treatment plans.\n",
      "* **Nike's Digital Design Studio**: A platform that uses Generative AI to design new sneakers, clothing, and accessories.\n",
      "* **Google's Image Recognition**: A system that uses Generative AI to recognize objects in images and create realistic renderings of 3D models.\n",
      "\n",
      "Overall, Generative AI has the potential to transform various industries by providing insights, automating tasks, and enhancing customer experiences.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, and product descriptions. This can help businesses save time and money on content creation while maintaining consistency and quality.\n",
      "2. **Marketing Automation**: Generative AI can be used to create personalized marketing campaigns by generating customized content, product recommendations, and customer communication.\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, such as 3D models, product prototypes, and packaging designs. This can help businesses reduce design costs and improve product development timelines.\n",
      "4. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can understand customer inquiries and provide personalized responses. This can help businesses improve their customer service experience while reducing costs.\n",
      "5. **Business Intelligence and Analytics**: Generative AI can be used to analyze large datasets, identify patterns, and generate insights. This can help businesses make data-driven decisions and improve their overall performance.\n",
      "6. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, helping businesses reduce downtime and improve equipment lifespan.\n",
      "7. **Language Translation**: Generative AI can be used to translate languages in real-time, helping businesses communicate with customers and partners across language barriers.\n",
      "8. **Financial Modeling**: Generative AI can be used to create financial models, forecast revenue and expenses, and predict market trends. This can help businesses make more accurate financial decisions and improve their overall performance.\n",
      "9. **Supply Chain Optimization**: Generative AI can be used to optimize supply chains by predicting demand, identifying bottlenecks, and recommending optimal inventory levels.\n",
      "10. **Security and Fraud Detection**: Generative AI can be used to detect and prevent security threats, such as phishing attacks and credit card fraud.\n",
      "\n",
      "Some specific examples of business applications of Generative AI include:\n",
      "\n",
      "* **Salesforce's Einstein**: A generative AI platform that uses machine learning to analyze customer data and provide personalized sales recommendations.\n",
      "* **HubSpot's AI-powered Chatbots**: A chatbot system that uses generative AI to understand customer inquiries and provide personalized responses.\n",
      "* **Dell Technologies' Generative Design**: A software tool that uses generative AI to design new products, such as 3D models and product prototypes.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases emerge across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4b6c5-f3e4-48e2-b3c8-9f1945b86f74",
   "metadata": {},
   "source": [
    "註：  \n",
    "api_key='ollama'  \n",
    "=> 雖然 OpenAI SDK 需要 api_key，但 Ollama 不會檢查，因此隨便填也可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as text, images, videos, and music. This can be useful for companies that need to create large amounts of content quickly, such as news organizations, educational institutions, or marketing firms.\n",
      "2. **Personalization**: Generative AI can help personalize customer experiences by generating personalized product recommendations, advertisements, and marketing materials. This can lead to increased customer engagement and loyalty.\n",
      "3. **Predictive Analytics**: Generative AI can be used to analyze large amounts of data and generate predictive models that can forecast future events or trends. This can be useful for companies that want to stay ahead of the competition or make informed business decisions.\n",
      "4. **Customer Service**: Generative AI can help automate customer service by generating responses to common inquiries, resolving simple issues, and providing basic support. This can free up human customer support agents to focus on more complex issues.\n",
      "5. **Innovation and Research**: Generative AI can be used to generate new ideas, hypotheses, and solutions for complex problems. This can be useful for companies that want to stay innovative and competitive in their field.\n",
      "6. **Automated Design**: Generative AI can be used to automate the design process for products such as fashion items, furniture, or architecture. This can save time and reduce costs associated with traditional design methods.\n",
      "7. **Healthcare**: Generative AI can help analyze medical images, generate new treatment plans, and provide personalized medicine recommendations. This can lead to improved patient outcomes and more efficient healthcare services.\n",
      "8. **Marketing Campaigns**: Generative AI can be used to create targeted marketing campaigns by generating personalized content, emails, and social media posts based on customer data and behavior.\n",
      "9. **Autonomous Systems**: Generative AI can be used to develop autonomous systems that can learn and adapt autonomously, such as self-driving cars or drones.\n",
      "10. **Financial Services**: Generative AI can help analyze financial patterns, generate new investment ideas, and automate trading decisions. This can lead to improved investment returns and reduced risk.\n",
      "\n",
      "Some specific business scenarios where generative AI is being used include:\n",
      "\n",
      "* **Virtual stylists**: Using generative AI to create personalized clothing and accessory suggestions for customers based on their fashion preferences.\n",
      "* **Automated advertising**: Using generative AI to generate targeted advertisements for social media platforms and online publications.\n",
      "* **Predictive demand forecasting**: Using generative AI to analyze sales data and predict future demand for products.\n",
      "* **Medical diagnosis**: Using generative AI to help doctors diagnose complex medical conditions based on patient radiology images.\n",
      "* **Automated language translation**: Using generative AI to provide real-time language translation for customers who speak different languages.\n",
      "\n",
      "Overall, the business applications of generative AI are vast and varied, and are only limited by the imagination and creativity of businesses looking to leverage this technology.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ��� \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8... 100% ������������������������������������������������������ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e... 100% ������������������������������������������������������  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f... 100% ������������������������������������������������������ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd... 100% ������������������������������������������������������  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e... 100% ������������������������������������������������������  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to define some core concepts related to Large Language Models (LLMs) like \"neural networks\" and the \"attention mechanism,\" as well as the Transformer. Hmm, let me start by breaking down each term.\n",
      "\n",
      "Starting with neural networks—they must be a group of interconnected nodes or neurons that process information in a layered structure. Yeah, something like processing input data through layers where each layer transforms the data until it's fully processed. The output is usually something we use for tasks like language modeling.\n",
      "\n",
      "Then there's the attention mechanism. I remember this from some reading; maybe it's about how models focus on specific parts of the input for processing information? Like, in a sequence, the model can highlight which parts are most relevant to the task at hand by paying attention to their context and embedding representations. That makes sense because each word has a unique representation that helps prioritize more important words when making predictions.\n",
      "\n",
      "Now, the Transformer. From what I've seen, it's an architecture where each position in a sequence is handled independently. The key here is the self-attention mechanism where each token can attend to all others, creating parallel computation within the model. It relies solely on the self-attention process for processing text, which means models like BPE or CLAude don't have traditional layers and only use this attention-based approach.\n",
      "\n",
      "Putting it all together, an LLM uses a neural network with the Transformer, processed through attention to understand sequences effectively, leveraging each token's context in parallel without relying on external features. That gives them really powerful models for generating and understanding language.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs) are a class of artificial intelligence systems designed to produce human-like text or speech across various domains. They are trained using vast amounts of data from large texts, including books, academic papers, Wikipedia articles, Twitter posts, YouTube videos, news articles, scientific papers, and other sources.\n",
      "\n",
      "### Neural Networks\n",
      "\n",
      "A neural network consists of interconnected nodes (also called neurons) loosely inspired by the structure of individual neurons in the human brain. These are connected together to form layers, which process the input data sequentially until it is fully processed into an output representation. Typically, this involves multiple layers of processing:\n",
      "\n",
      "1. **Input Layer**: Takes raw input, such as a text sequence.\n",
      "2. **Forward Pass**: Transforms the input through layers, computing representations (embeddings) for each node in the layer to form intermediate outputs.\n",
      "3. **Layer Output**: Outputs the final representation from which tasks are performed, such as language modeling or task understanding.\n",
      "\n",
      "### Attention Mechanism\n",
      "\n",
      "In a neural network, attention computes the relevance of a feature across all other data points by determining how much each feature should contribute to processing others. Mathematically, for each word <w>,注意力 scores are computed based on how \"related\" <w> is with other words via some query-key-value transformation.\n",
      "\n",
      "### Transformer\n",
      "\n",
      "The Transformer architecture involves one or more layers that process the input simultaneously rather than sequentially, which allows it to focus on different parts of text when generating output. The key is self-attention and its independence from positional information:\n",
      "\n",
      "1. **Self-Attention**: A mechanism where each token can attend to all others in parallel. This means the model computes the similarity between sequences without relying on their order.\n",
      "\n",
      "2. **Independent of Positional Information**: In this setup, positional encoding isn't explicitly used; instead, the model relies entirely on self-attention for processing text inputs.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
